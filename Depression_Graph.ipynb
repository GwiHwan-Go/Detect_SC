{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GwiHwan-Go/Detect_SC/blob/main/Depression_Graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 수집한 데이터로 Word Graph 만들기"
      ],
      "metadata": {
        "id": "gk1y-Wltnjna"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 제공하는 데이터 설명\n",
        "\n",
        "1. 데이터 설명 : DCinside 라는 커뮤니티에서 우울증 갤러리라는 곳의 게시물들의 '제목'들.\n",
        "2. 데이터 오버뷰\n",
        "\n",
        "  - 데이터 크기 : 2,470,236 개\n",
        "\n",
        "  - 데이터 피쳐 : title (텍스트 데이터), author (작성자 id), date (작성 날짜)\n",
        "  \n",
        "3. 텍스트 데이터 : 미리 학습시킨 토크나이저로 토큰화한 데이터로 ' '로 구분되어 있음.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mPRs3TiWnoKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 다운로드, 파일명은 sns_data.csv \n",
        "file_name = 'sns_data.csv'\n",
        "!wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-4qx3IRyXUtb_QSItiWyIHZIo9hcBttg' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-4qx3IRyXUtb_QSItiWyIHZIo9hcBttg\" -O $file_name && rm -rf ~/cookies.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNzCLUbVnqm1",
        "outputId": "4125b534-c5a4-41aa-b69e-60730778a79d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-31 06:29:30--  https://docs.google.com/uc?export=download&confirm=t&id=1-4qx3IRyXUtb_QSItiWyIHZIo9hcBttg\n",
            "Resolving docs.google.com (docs.google.com)... 142.250.159.113, 142.250.159.101, 142.250.159.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.250.159.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0o-30-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/gqqfqvn22rrsk27dn8imkh5mrton4vet/1667197725000/15740322463873228959/*/1-4qx3IRyXUtb_QSItiWyIHZIo9hcBttg?e=download&uuid=3cd0caec-a8e7-472b-b451-745901f032de [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-10-31 06:29:30--  https://doc-0o-30-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/gqqfqvn22rrsk27dn8imkh5mrton4vet/1667197725000/15740322463873228959/*/1-4qx3IRyXUtb_QSItiWyIHZIo9hcBttg?e=download&uuid=3cd0caec-a8e7-472b-b451-745901f032de\n",
            "Resolving doc-0o-30-docs.googleusercontent.com (doc-0o-30-docs.googleusercontent.com)... 74.125.70.132, 2607:f8b0:4001:c02::84\n",
            "Connecting to doc-0o-30-docs.googleusercontent.com (doc-0o-30-docs.googleusercontent.com)|74.125.70.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 156905939 (150M) [text/csv]\n",
            "Saving to: ‘sns_data.csv’\n",
            "\n",
            "sns_data.csv        100%[===================>] 149.64M   171MB/s    in 0.9s    \n",
            "\n",
            "2022-10-31 06:29:32 (171 MB/s) - ‘sns_data.csv’ saved [156905939/156905939]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터 살펴보기\n",
        "data = pd.read_csv(file_name, low_memory=False, index_col=0) \n",
        "first_date, last_date = data.loc[0,'date'], data.loc[data.shape[0]-1,'date']\n",
        "print(\"수집한 게시물 범위 :\", first_date, \"~\", last_date, \"\\n\" \\\n",
        "      \"수집된 데이터 크기 :\", data.shape[0], \"\\n수집한 데이터 features :\", data.columns)\n",
        "data.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "UoX5ZUABoHoo",
        "outputId": "c8717e12-8c2b-438b-c652-56c1772b4532"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "수집한 게시물 범위 : 2021-03-03 ~ 2022-10-27 \n",
            "수집된 데이터 크기 : 2470236 \n",
            "수집한 데이터 features : Index(['title', 'author', 'date'], dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         title  author        date\n",
              "2470231               나 병신 ...   16125  2022-10-27\n",
              "2470232       나고 닉 글 올리 규 싶 읃데   12779  2022-10-27\n",
              "2470233       씨발 남자 직원 음식 깔아 주    5291  2022-10-27\n",
              "2470234       나도 근데 아이디 두 번 바꿈   15378  2022-10-27\n",
              "2470235  알바 바보 쉨 ㅋㅋㅋ 나도 차단 해봐라   16125  2022-10-27"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96f17386-5a93-43ca-b343-21868046e296\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2470231</th>\n",
              "      <td>나 병신 ...</td>\n",
              "      <td>16125</td>\n",
              "      <td>2022-10-27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2470232</th>\n",
              "      <td>나고 닉 글 올리 규 싶 읃데</td>\n",
              "      <td>12779</td>\n",
              "      <td>2022-10-27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2470233</th>\n",
              "      <td>씨발 남자 직원 음식 깔아 주</td>\n",
              "      <td>5291</td>\n",
              "      <td>2022-10-27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2470234</th>\n",
              "      <td>나도 근데 아이디 두 번 바꿈</td>\n",
              "      <td>15378</td>\n",
              "      <td>2022-10-27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2470235</th>\n",
              "      <td>알바 바보 쉨 ㅋㅋㅋ 나도 차단 해봐라</td>\n",
              "      <td>16125</td>\n",
              "      <td>2022-10-27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96f17386-5a93-43ca-b343-21868046e296')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-96f17386-5a93-43ca-b343-21868046e296 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-96f17386-5a93-43ca-b343-21868046e296');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 혹시 모를, nan 값을 제거해주자. 제거해주지 않으면 float 이 발견되었다고 오류가 뜬다.\n",
        "print(f\"NAN 제거 전 데이터 수 = {data.shape}\")\n",
        "data = data[data.title.isna()==False]\n",
        "data = data.reset_index(drop=True)\n",
        "print(f\"NAN 제거 후 데이터 수 = {data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8AkXcbpoToS",
        "outputId": "d2a8d04e-4c23-4b65-dc14-458f1c7b7f93"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAN 제거 전 데이터 수 = (2470236, 3)\n",
            "NAN 제거 후 데이터 수 = (2469803, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install soynlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc2CqLVRoCrV",
        "outputId": "6ff9f7b8-0a49-492d-f495-53fe4777c7e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: soynlp in /usr/local/lib/python3.7/dist-packages (0.0.493)\n",
            "Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (5.4.8)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PMI 분석\n",
        "\n",
        "출처 : [SoyNLP 공식문서](!https://github.com/lovit/soynlp/blob/master/tutorials/pmi_usage.ipynb)\n",
        "\n",
        "이제 마지막 단계이다.\n",
        "\n",
        "단어들 간의 연관관계를 분석해서 자살 관련 정보 파악에 도움이 되는 __다른 단어__들은 무엇이 있는 지 알아보자.\n",
        "\n",
        "PMI 분석은\n",
        "\n",
        "(word, contexts) 혹은 (input, outputs)의 상관성을 측정하는 방법으로, pmi 값이 클수록 두 변수의 상관성이 크다.\n",
        "\n",
        "이를 위해서 특정 단어와 그 주위 단어들을 저장하는 행렬인 Word-Contexts Matrix를 생성한다."
      ],
      "metadata": {
        "id": "XwsT-QZenzwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 코드는 정제된 데이터를 통해서\n",
        "\n",
        "word_contexts matrix를 가지고 있는 pmi 인스턴스를 생성한다.(인스턴스 생성은 3분정도 걸림)\n",
        "\n",
        "생성된 pmi 인스턴스를 통해 수집한 데이터 속 단어들의 문맥과 유사 단어들을 알 수 있다."
      ],
      "metadata": {
        "id": "3l96WomGn1uH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from soynlp.word import pmi as pmi_func\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from soynlp.vectorizer import sent_to_word_contexts_matrix\n",
        "import numpy as np\n",
        "\n",
        "def custom_tokenizer(sents) :\n",
        "  # 그래프의 차원을 줄여주기 위해서 단어 길이가 1인 건 다 없애준다.\n",
        "  return [word for word in sents.split() if len(word) > 1]\n",
        "\n",
        "class Pmi() :\n",
        "\n",
        "  def __init__(self, text_data) :\n",
        "\n",
        "    self.mat, self.idx2vocab = sent_to_word_contexts_matrix(\n",
        "        text_data,\n",
        "        windows=3,\n",
        "        min_tf=10,\n",
        "        tokenizer= lambda x : custom_tokenizer(x), # (default) lambda x:x.split(),\n",
        "        dynamic_weight=False,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    self.pmi, self.px, self.py = pmi_func(\n",
        "        self.mat,\n",
        "        min_pmi = 0,\n",
        "        alpha = 0.0,\n",
        "        beta = 0.75\n",
        "    )\n",
        "\n",
        "    self.vocab2idx = {vocab:idx for idx, vocab in enumerate(self.idx2vocab)}\n",
        "\n",
        "  def context_words(self ,target, topk=10) :\n",
        "    \"\"\"\n",
        "    :target: str\n",
        "        String type query word\n",
        "    :param topk: int\n",
        "        Maximum number of similar items.\n",
        "        If set top as negative value, it returns similarity with all words\n",
        "    Returns\n",
        "    ----------\n",
        "    similars : list of tuple\n",
        "        List contains tuples (item, cosine similarity)\n",
        "        Its length is topk\n",
        "    \"\"\"\n",
        "    query = self.vocab2idx[target]\n",
        "\n",
        "    submatrix = self.pmi[query, :].tocsr() # get the row of query\n",
        "    contexts = submatrix.nonzero()[1] # nonzero() return (rows, columns)\n",
        "    pmi_i = submatrix.data\n",
        "\n",
        "    most_relateds = [(idx, pmi_ij) for idx, pmi_ij in zip(contexts, pmi_i)]\n",
        "    most_relateds = sorted(most_relateds, key=lambda x:-x[1])[:topk]\n",
        "    most_relateds = [[idx, pmi_ij] for idx, pmi_ij in most_relateds]\n",
        "\n",
        "    most_relateds = [(self.idx2vocab[idx], pmi_ij) for idx, pmi_ij in most_relateds]\n",
        "\n",
        "    return most_relateds\n",
        "\n",
        "  def similar_words(self, target, topk=10):\n",
        "      \"\"\"\n",
        "      :target: str\n",
        "          String type query word\n",
        "      :param topk: int\n",
        "          Maximum number of similar items.\n",
        "          If set top as negative value, it returns similarity with all words\n",
        "      Returns\n",
        "      ----------\n",
        "      similars : list of tuple\n",
        "          List contains tuples (item, cosine similarity)\n",
        "          Its length is topk\n",
        "      \"\"\"\n",
        "\n",
        "      q = self.vocab2idx.get(target, -1)\n",
        "      if q == -1:\n",
        "          return []\n",
        "\n",
        "      qvec = self.pmi[q].reshape(1,-1)\n",
        "      dist = pairwise_distances(qvec, self.pmi, metric='cosine')[0]\n",
        "      sim_idxs = dist.argsort()\n",
        "\n",
        "      if topk > 0:\n",
        "          sim_idxs = sim_idxs[:topk+1]\n",
        "\n",
        "      results = [[idx, 1 - dist[idx]] for idx in sim_idxs if idx != q]\n",
        "      # results = np.array(results)\n",
        "      results = [(self.idx2vocab[idx], pmi_ij) for idx, pmi_ij in results]\n",
        "\n",
        "      return results\n",
        "\n",
        "  def np_context_words(self ,target, topk=10) :\n",
        "    \"\"\"\n",
        "    효율적인 그래프 생성을 위한 코드.\n",
        "    input(str) : a word\n",
        "    ----------\n",
        "    results : array of tuple\n",
        "        List contains tuples (item, similarity)\n",
        "        Its length is topk\n",
        "    \"\"\"\n",
        " \n",
        "    submatrix = self.pmi[target, :].tocsr() # get the row of query\n",
        "    contexts = submatrix.nonzero()[1] # nonzero() return (rows, columns)\n",
        "    pmi_i = submatrix.data\n",
        "\n",
        "    most_relateds = [(idx, pmi_ij) for idx, pmi_ij in zip(contexts, pmi_i)]\n",
        "    most_relateds = sorted(most_relateds, key=lambda x:-x[1])[:topk]\n",
        "    most_relateds = [[idx, pmi_ij] for idx, pmi_ij in most_relateds]\n",
        "    results = np.array(most_relateds)\n",
        "    # most_relateds = [(self.idx2vocab[idx], pmi_ij) for idx, pmi_ij in most_relateds]\n",
        "\n",
        "    return results\n",
        "\n",
        "  def np_similar_words(self, target, topk=10):\n",
        "      \"\"\"\n",
        "      효율적인 그래프 생성을 위한 코드.\n",
        "      input(str) : a word\n",
        "      ----------\n",
        "      results : array of tuple\n",
        "          List contains tuples (item, cosine similarity)\n",
        "          Its length is topk\n",
        "      \"\"\"\n",
        "\n",
        "      qvec = self.pmi[target].reshape(1,-1)\n",
        "      dist = pairwise_distances(qvec, self.pmi, metric='cosine')[0]\n",
        "      sim_idxs = dist.argsort()\n",
        "\n",
        "      if topk > 0:\n",
        "          sim_idxs = sim_idxs[:topk+1]\n",
        "\n",
        "      results = [[idx, 1 - dist[idx]] for idx in sim_idxs if idx != q]\n",
        "      results = np.array(results)\n",
        "\n",
        "      return results\n",
        "  \n",
        "  def idx_to_word(self, indices_list) :\n",
        "    \n",
        "    return [self.idx2vocab[index] for index in indices_list]\n",
        "\n",
        "  def word_to_idx(self, word_list) :\n",
        "\n",
        "    return [self.vocab2idx[word] for word in word_list]\n",
        "\n",
        "pmi = Pmi(data.title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc5gpm45n2Ms",
        "outputId": "65f7ccba-b725-45bd-d099-ce9630340ce4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create (word, contexts) matrix\n",
            "  - counting word frequency from 2469802 sents, mem=1.105 Gb\n",
            "  - scanning (word, context) pairs from 2469802 sents, mem=1.593 Gb\n",
            "  - (word, context) matrix was constructed. shape = (47605, 47605)                    \n",
            "  - done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pmi.idx2vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzJYCJm2vIkP",
        "outputId": "aa5b87db-3809-4e20-ef8f-411e23fde314"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47605"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph 만들기\n",
        "\n",
        "생성한 Pmi 인스턴스로, \n",
        "\n",
        "유사 단어 그래프와 문맥 단어 그래프를 만들어 보자."
      ],
      "metadata": {
        "id": "vVwOL6HFopJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph 생성 알고리즘\n",
        "\n",
        "```python\n",
        "until recursion boundary :\n",
        "  Seed -> Context_word_list\n",
        "    for Context_word in Context_word_list\n",
        "      build graph\n",
        "```\n",
        "\n",
        "그래프 생성에서 중요한 파라미터가 두가지 있다. 이 두가지를 크게 잡으면 좋겠지만, 그러다가 ram의 용량이 다차서 colab 세션이 다운될 수도 있으니 주의하자.\n",
        "- max_recursion : 그래프 생성은 재귀의 형식이다, 재귀를 몇 번까지 허용할 것이냐를 정한다.\n",
        "- graph_boundary : 웨이트를 몇까지 허용할 것이냐를 정한다. \n",
        "\n"
      ],
      "metadata": {
        "id": "dHQV0qFcxJfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network = np.empty((len(pmi.idx2vocab),len(pmi.idx2vocab)), dtype=np.float16)\n",
        "network.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9QYBhtZrJSa",
        "outputId": "ecfd620b-c66b-41ac-c87d-bace223dcc23"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47605, 47605)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import sparse\n",
        "from tqdm import tqdm\n",
        "def make_network_array(node,current_recursion=0,graph_boundary=5,max_recursion=10,alpha=0.7) :\n",
        "\n",
        "  global network\n",
        "\n",
        "  context_words = pmi.np_context_words(node,topk=30) #context 뽑아오기\n",
        "  context_words = context_words[np.where(context_words[:,1] > graph_boundary),:][0]\n",
        "\n",
        "  if context_words.shape[0] == 0 :\n",
        "    return []\n",
        "\n",
        "  indices = np.array(context_words[:,0], dtype='int32')\n",
        "  alpha = alpha**current_recursion\n",
        "\n",
        "  network[int(node),indices]=context_words[:,1]*alpha\n",
        "  # print(int(node), \"-->\", indices)\n",
        "  if current_recursion <= max_recursion :\n",
        "    for id in context_words[:,0] :\n",
        "      make_network_array(id,\n",
        "                        current_recursion=current_recursion+1,\n",
        "                        graph_boundary=graph_boundary,\n",
        "                        max_recursion=max_recursion)\n",
        "  else :\n",
        "    return []\n",
        "\n",
        "seeds = ['자살','동반',\n",
        "        '죽을래','투신','자해','죽고싶다','우울','살자',\n",
        "        '인생','죽음']\n",
        "\n",
        "graph_boundary = 3.5\n",
        "max_recursion = 2\n",
        "\n",
        "for seed in tqdm(pmi.word_to_idx(seeds)) :\n",
        "    make_network_array(int(seed),\n",
        "                  current_recursion=0,\n",
        "                  graph_boundary=graph_boundary,\n",
        "                  max_recursion=max_recursion)\n",
        "\n",
        "\n",
        "from scipy.sparse import csr_matrix\n",
        "network_name='network.npz'\n",
        "sparse.save_npz(network_name,csr_matrix(network))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o95TPIdmq17t",
        "outputId": "c55a3f28-15b8-4f34-c041-d9d15746114b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:12<01:56, 12.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:27<01:50, 13.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:54<02:19, 20.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [01:11<01:53, 18.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [01:29<01:31, 18.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [01:44<01:08, 17.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [01:56<00:46, 15.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [02:09<00:29, 14.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [02:22<00:14, 14.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:32<00:00, 15.26s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9u_mK7kcydJ-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Fe_Y2WDuJWT"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "\n",
        "sparse_matrix = scipy.sparse.load_npz(network_name)\n",
        "CG=nx.from_scipy_sparse_matrix(csr_network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-B25vzc8fGW"
      },
      "outputs": [],
      "source": [
        "# Weight 분포 보기\n",
        "import pandas as pd \n",
        "\n",
        "def show_w_e_dist(G) :\n",
        "  weights = [wt for (u, v, wt) in G.edges.data('weight')]\n",
        "  degrees = [G.degree(node) for node in G.nodes]\n",
        "  return pd.DataFrame(degrees), pd.DataFrame(weights)\n",
        "\n",
        "ds, ws = show_w_e_dist(CG)\n",
        "ds.describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ws.describe()"
      ],
      "metadata": {
        "id": "RYqU9m71r_bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## idx -> word\n",
        "relabel_nodes = {idx : word for idx, word in enumerate(pmi.idx2vocab)}\n",
        "CG = nx.relabel_nodes(CG, relabel_nodes)"
      ],
      "metadata": {
        "id": "j5D9gPjQsBm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## filter node which has less edges.\n",
        "minimum_edges = 33\n",
        "CG_fnodes = nx.subgraph_view(CG, \n",
        "                          filter_node=lambda x : CG.degree[x]>=minimum_edges) \n",
        "print(f\"n(nodes) : {CG.number_of_nodes()} ---> {CG_fnodes.number_of_nodes()}\")"
      ],
      "metadata": {
        "id": "RvvTfkPGsDBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## filter edges which has less weights.\n",
        "\n",
        "minimum_weight = 1.337664\n",
        "\n",
        "def filter_edge(n1, n2):\n",
        "    return CG_fnodes[n1][n2]['weight'] > minimum_weight\n",
        "\n",
        "CG_fnodes_fedges = nx.subgraph_view(CG_fnodes, \n",
        "                                    filter_node = lambda x : True,\n",
        "                                    filter_edge=filter_edge) \n",
        "print(f\"n(edges) : {CG_fnodes.number_of_edges()} ---> {CG_fnodes_fedges.number_of_edges()}\")\n"
      ],
      "metadata": {
        "id": "VDY7Hgy8sF5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page_rank_results = nx.pagerank(CG_fnodes_fedges)"
      ],
      "metadata": {
        "id": "C2y29LUvsIuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{key:rank for key,rank in sorted(page_rank_results.items(),key=lambda x:x[1],reverse=True) if len(key) > 1}"
      ],
      "metadata": {
        "id": "Cpqqx1bTsJ29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZO2A_5UwlI6"
      },
      "outputs": [],
      "source": [
        "seeds = ['자살', '자해', '동반', '우울', '죽음']\n",
        "graph_boundary = 3\n",
        "max_recursion = 15\n",
        "ids = pmi.word_to_idx(seeds)\n",
        "CG2 = nx.DiGraph()\n",
        "\n",
        "for seed in tqdm(pmi.word_to_idx(seeds)) :\n",
        "  CG2.add_node(seed)\n",
        "  plot_graph(seed,\n",
        "            current_recursion=0,\n",
        "            graph_boundary=graph_boundary,\n",
        "            max_recursion=max_recursion)\n",
        "\n",
        "graph_name = './results/PMI_words_graph2.pickle'\n",
        "# save graph object to file\n",
        "pickle.dump(CG2, open(graph_name, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2JZnjxEuRjW"
      },
      "outputs": [],
      "source": [
        "CG = pickle.load(open(graph_name, 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMmjejQovpeY"
      },
      "outputs": [],
      "source": [
        "# pos = nx.spring_layout(CG) \n",
        "# labels =nx.get_edge_attributes(CG,'weight')\n",
        "# nx.draw_networkx_edge_labels(CG, pos, edge_labels = labels) \n",
        "nx.draw(CG, pos,with_labels = True, font_weight = \"bold\") "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nx.write_gexf(CG_fnodes_fedges, \"./models/context_graph_final.gexf\") "
      ],
      "metadata": {
        "id": "7uNftr97sRxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeS7WR6vv_cH"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pylab\n",
        "import networkx as nx\n",
        "\n",
        " def save_graph(graph,file_name):\n",
        "    #initialze Figure\n",
        "    plt.figure(num=None, figsize=(20, 20), dpi=80)\n",
        "    plt.axis('off')\n",
        "    fig = plt.figure(1)\n",
        "    pos = nx.spring_layout(graph)\n",
        "    nx.draw_networkx_nodes(graph,pos)\n",
        "    nx.draw_networkx_edges(graph,pos)\n",
        "    nx.draw_networkx_labels(graph,pos)\n",
        "\n",
        "    cut = 1.00\n",
        "    xmax = cut * max(xx for xx, yy in pos.values())\n",
        "    ymax = cut * max(yy for xx, yy in pos.values())\n",
        "    plt.xlim(0, xmax)\n",
        "    plt.ylim(0, ymax)\n",
        "\n",
        "    plt.savefig(file_name,bbox_inches=\"tight\")\n",
        "    pylab.close()\n",
        "    del fig\n",
        "\n",
        "#Assuming that the graph g has nodes and edges entered\n",
        "save_graph(g,\"my_graph.pdf\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyOuAtMAQV/dW+ki4bbOQul3",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}