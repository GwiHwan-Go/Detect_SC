{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/9dV5q2RKnkqtOdoeyeXo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GwiHwan-Go/Detect_SC/blob/main/Data_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 수집한 데이터를 분석해 봅시다.\n",
        "\n",
        "##### 본 스크립트의 코드들은 대부분 1-2시간 정도의 연산 시간을 필요로 합니다.\n",
        "##### 실질적인 데이터 분석 및 시각화는 Data_Visualization 스크립트를 참고해주세요.\n",
        "\n",
        "참고 자료 : [딥러닝을 이용한 자연어 처리 입문](!https://wikidocs.net/92961), [SoyNLP 공식 문서](!https://github.com/lovit/soynlp)"
      ],
      "metadata": {
        "id": "QKxKO17zDJGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 준비 사항\n",
        "\n",
        "본 파일은 체험용 코드입니다.\n",
        "\n",
        "실제로 본 파일에 사용된 데이터는 240만 개의 게시글이며, \n",
        "\n",
        "여기서는 간단한 체험을 위해서 체험용 데이터를 제공합니다. \n",
        "\n",
        "또한, 미리 훈련시킨 soyNLP Tokenizer 를 제공하며, \n",
        "\n",
        "다운로드 방법은 아래에서 설명할 것입니다.\n",
        "\n",
        "(수정중)"
      ],
      "metadata": {
        "id": "SFmnvLhjZmen"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAx1DAneod1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "348a9826-4f79-42ec-9355-8bd8d5eb5ab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Detect_SC_symptoms\n"
          ]
        }
      ],
      "source": [
        "# This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "FOLDERNAME = 'Detect_SC_symptoms'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/{}'.format(FOLDERNAME))\n",
        "\n",
        "# Change dariectory to current folder\n",
        "%cd /content/drive/MyDrive/$FOLDERNAME"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install soynlp\n",
        "!pip install konlpy\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "eTkSwjJaZ218"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과물 저장 경로\n",
        "save_dir = \"/content/drive/MyDrive/Detect_SC_symptoms/results\"\n",
        "file_name = \"refined_full_custom_tokenizer.csv\" # tokenized X = refined_full.csv / with Okt tokenizer = refined_full_okt_tokenized.csv\n",
        "data_path = f\"/content/drive/MyDrive/Detect_SC_symptoms/results/{file_name}\" \n",
        "data = pd.read_csv(data_path, low_memory=False, index_col=0) \n",
        "first_id, last_id = data.loc[0,'id'], data.loc[data.shape[0]-1,'id']\n",
        "print(\"수집한 게시물 범위 :\", first_id, \"~\", last_id, \"\\n\" \\\n",
        "      \"수집된 데이터 크기 :\", data.shape[0], \"\\n수집한 데이터 features :\", data.columns)\n",
        "data.tail()"
      ],
      "metadata": {
        "id": "325bw-IdzH15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "6716575e-1362-4c13-b34f-5fb4c3de21dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "수집한 게시물 범위 : 2 ~ 4445728 \n",
            "수집된 데이터 크기 : 2470236 \n",
            "수집한 데이터 features : Index(['id', 'title', 'author', 'date', 'link'], dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              id                  title        author        date  \\\n",
              "2470231  4445724               나 병신 ...            민애  2022-10-27   \n",
              "2470232  4445725       나고 닉 글 올리 규 싶 읃데  조팡이(118.235)  2022-10-27   \n",
              "2470233  4445726       씨발 남자 직원 음식 깔아 주   연우ㅗ(223.62)  2022-10-27   \n",
              "2470234  4445727       나도 근데 아이디 두 번 바꿈           .O2  2022-10-27   \n",
              "2470235  4445728  알바 바보 쉨 ㅋㅋㅋ 나도 차단 해봐라            민애  2022-10-27   \n",
              "\n",
              "                                                      link  \n",
              "2470231  https://m.dcinside.com/board/depression_new1/4...  \n",
              "2470232  https://m.dcinside.com/board/depression_new1/4...  \n",
              "2470233  https://m.dcinside.com/board/depression_new1/4...  \n",
              "2470234  https://m.dcinside.com/board/depression_new1/4...  \n",
              "2470235  https://m.dcinside.com/board/depression_new1/4...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01b6d49e-935d-47b3-b2ba-b72cef70f0fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>date</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2470231</th>\n",
              "      <td>4445724</td>\n",
              "      <td>나 병신 ...</td>\n",
              "      <td>민애</td>\n",
              "      <td>2022-10-27</td>\n",
              "      <td>https://m.dcinside.com/board/depression_new1/4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2470232</th>\n",
              "      <td>4445725</td>\n",
              "      <td>나고 닉 글 올리 규 싶 읃데</td>\n",
              "      <td>조팡이(118.235)</td>\n",
              "      <td>2022-10-27</td>\n",
              "      <td>https://m.dcinside.com/board/depression_new1/4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2470233</th>\n",
              "      <td>4445726</td>\n",
              "      <td>씨발 남자 직원 음식 깔아 주</td>\n",
              "      <td>연우ㅗ(223.62)</td>\n",
              "      <td>2022-10-27</td>\n",
              "      <td>https://m.dcinside.com/board/depression_new1/4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2470234</th>\n",
              "      <td>4445727</td>\n",
              "      <td>나도 근데 아이디 두 번 바꿈</td>\n",
              "      <td>.O2</td>\n",
              "      <td>2022-10-27</td>\n",
              "      <td>https://m.dcinside.com/board/depression_new1/4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2470235</th>\n",
              "      <td>4445728</td>\n",
              "      <td>알바 바보 쉨 ㅋㅋㅋ 나도 차단 해봐라</td>\n",
              "      <td>민애</td>\n",
              "      <td>2022-10-27</td>\n",
              "      <td>https://m.dcinside.com/board/depression_new1/4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01b6d49e-935d-47b3-b2ba-b72cef70f0fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01b6d49e-935d-47b3-b2ba-b72cef70f0fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01b6d49e-935d-47b3-b2ba-b72cef70f0fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"중복, NAN 제거 전 데이터 수 = {data.shape}\")\n",
        "data = data.drop_duplicates(['id'])\n",
        "data = data[data.title.isna()==False]\n",
        "data = data.reset_index(drop=True)\n",
        "print(f\"중복, NAN 제거 후 데이터 수 = {data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKx4hSrZxnbX",
        "outputId": "73d0434a-7b36-4464-b02b-73f93720f60e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "중복, NAN 제거 전 데이터 수 = (2470236, 5)\n",
            "중복, NAN 제거 후 데이터 수 = (2470236, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 게시글을 전처리 해보자.\n",
        "\n",
        "1. Hanspell -> 신조어에 대응을 아예 못함\n",
        "2. SoyNLP 를 이용해, 모은 자료들을 통해서 학습시킴.\n",
        "\n",
        "   -> 신조어나 형태소 분석기에 등록되지 않은 단어를 잘 구분해줄 수 있음."
      ],
      "metadata": {
        "id": "kSlsZ3gV3_Y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hanspell, koNLPY 예제\n",
        "!pip install git+https://github.com/ssut/py-hanspell.git\n",
        "!pip install konlpy\n",
        "\n",
        "from hanspell import spell_checker\n",
        "\n",
        "for sent in data.title[-20:] :\n",
        "  okt = Okt()\n",
        "  print('before :', sent)\n",
        "  spelled_sent = spell_checker.check(sent)\n",
        "\n",
        "  hanspell_sent = spelled_sent.checked\n",
        "  print('after :', hanspell_sent)\n",
        "  print('after :', okt.pos(sent, stem=True))"
      ],
      "metadata": {
        "id": "5OIiP7_W-OYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from soynlp.word import WordExtractor\n",
        "\n",
        "model_fname=\"/content/drive/MyDrive/Detect_SC_symptoms/models\" + \"/\" + \"soy_wordExtractor_full.model\"\n",
        "\n",
        "##SoyNLP 훈련 및 저장 코드 - 30분 걸림##\n",
        "\n",
        "# word_extractor = WordExtractor()\n",
        "# word_extractor.train(data[data.title.isna()==False].title)\n",
        "# word_score_table = word_extractor.extract()\n",
        "# word_extractor.save(model_fname)\n",
        "\n",
        "##SoyNLP 훈련 및 저장 코드 - 30분 걸림##"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg7UZWJzd-am",
        "outputId": "377bbf92-337e-4d51-ec46-918e5066c52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training was done. used memory 6.691 Gb\n",
            "all cohesion probabilities was computed. # words = 480337\n",
            "all branching entropies was computed # words = 523918\n",
            "all accessor variety was computed # words = 523918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from soynlp.tokenizer import LTokenizer\n",
        "\n",
        "## Word_Extractor param 설정 및 로드\n",
        "word_extractor = WordExtractor(min_frequency=10,\n",
        "                               min_cohesion_forward=5.0,\n",
        "                               min_right_branching_entropy=0.0)\n",
        "word_extractor.load(model_fname)\n",
        "\n",
        "## Cohesion 과 Entropy 계산해서 tokenizer 에 필요한 scores 계산\n",
        "scores = word_extractor.word_scores()\n",
        "scores = {key : (scores[key].cohesion_forward * math.exp(scores[key].right_branching_entropy)) \\\n",
        "          for key in scores.keys()}\n",
        "\n",
        "## tokenizer 생성\n",
        "tokenizer = LTokenizer(scores=scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsvzE94CfbQl",
        "outputId": "c4d43f03-8964-4495-d0db-04a755ac1df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all cohesion probabilities was computed. # words = 480337\n",
            "all branching entropies was computed # words = 523918\n",
            "all accessor variety was computed # words = 523918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## SoyNLP 사용 예 -> SoyNLP(tokenizer) -> okt pos tagger -> 불용어 제거\n",
        "from konlpy.tag import Okt\n",
        "from soynlp.normalizer import *\n",
        "\n",
        "\n",
        "def preprocess_tokenizer(sentence) : \n",
        "\n",
        "  pos_tagger = Okt()\n",
        "  # sentence = emoticon_normalize(sentence)\n",
        "  # sentence = repeat_normalize(sentence)\n",
        "\n",
        "  #soynlp tokenizer로 나눠준 후 konlpy Okt postagger로 품사 판별\n",
        "  return [word[0]\n",
        "          for word in pos_tagger.pos(' '.join(tokenizer.tokenize(sentence)))\n",
        "          if word[1] != 'Josa'] # 조사는 분석에서 제외\n",
        "\n",
        "#### 240m 건의 텍스트 데이터를 정제(토큰화 + 조사 제거)하는 작업 - 1시간 걸림 ####\n",
        "# from tqdm import tqdm\n",
        "# tqdm.pandas()\n",
        "# data.title = data.title.progress_apply(lambda x : ' '.join(preprocess_tokenizer(x)))  OR # data.title = data.title.progress_apply(lambda x : ' '.join(okt.morphs(x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfW3Bm4Dh4HB",
        "outputId": "eae8c2ac-ba31-4d1f-a1b6-b2646aaa549b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2470236/2470236 [57:28<00:00, 716.24it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PMI 분석\n",
        "\n",
        "\n",
        "단어들 간의 연관관계를 분석해서 자살 관련 정보 파악에 도움이 되는 __다른 단어__들은 무엇이 있는 지 알아보자.\n"
      ],
      "metadata": {
        "id": "_Lc8B1z7zgSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from soynlp.vectorizer import sent_to_word_contexts_matrix\n",
        "from scipy import sparse\n",
        "import pickle\n",
        "from soynlp.word import pmi as pmi_func\n",
        "\n",
        "mat_save_path = \"/content/drive/MyDrive/Detect_SC_symptoms/models/words_sparse_mat.npz\"\n",
        "index_list_save_path = \"/content/drive/MyDrive/Detect_SC_symptoms/models/idx_to_vocabs\"\n",
        "\n",
        "############ 텍스트 데이터를 정제,변환해서 주위 단어들과 함께 word matrix로 변환해주는 작업 - 2시간 30분 정도 걸림 ########\n",
        "# x, idx2vocab = sent_to_word_contexts_matrix(\n",
        "#     data.title,\n",
        "#     windows=3,\n",
        "#     min_tf=10,\n",
        "#     tokenizer= lambda x : okt.morphs(x), # (default) lambda x:x.split(),\n",
        "#     dynamic_weight=False,\n",
        "#     verbose=True\n",
        "# )\n",
        "\n",
        "# sparse.save_npz(mat_save_path, x)\n",
        "# with open(index_list_save_path, \"wb\") as fp:   #Pickling\n",
        "#   pickle.dump(idx2vocab, fp)\n",
        "############ 텍스트 데이터를 정제,변환해서 주위 단어들과 함께 word matrix로 변환해주는 작업 - 2시간 30분 정도 걸림 ########\n",
        "\n",
        "###Load Data\n",
        "\n",
        "x = sparse.load_npz(mat_save_path)\n",
        "with open(index_list_save_path, \"rb\") as fp:   # Unpickling\n",
        "  idx2vocab = pickle.load(fp)\n",
        "\n",
        "pmi, px, py = pmi_func(\n",
        "    x,\n",
        "    min_pmi = 0,\n",
        "    alpha = 0.0,\n",
        "    beta = 0.75\n",
        ")"
      ],
      "metadata": {
        "id": "kYCoGn58zyjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 특정 단어['살고 싶다']와 함께 등장한 단어들 상위 10개##\n",
        "target = '살고싶다'\n",
        "howmany = 10\n",
        "\n",
        "vocab2idx = {vocab:idx for idx, vocab in enumerate(idx2vocab)}\n",
        "query = vocab2idx[target]\n",
        "\n",
        "submatrix = pmi[query,:].tocsr() # get the row of query\n",
        "contexts = submatrix.nonzero()[1] # nonzero() return (rows, columns)\n",
        "pmi_i = submatrix.data\n",
        "\n",
        "most_relateds = [(idx, pmi_ij) for idx, pmi_ij in zip(contexts, pmi_i)]\n",
        "most_relateds = sorted(most_relateds, key=lambda x:-x[1])[:howmany]\n",
        "most_relateds = [(idx2vocab[idx], pmi_ij) for idx, pmi_ij in most_relateds]\n",
        "\n",
        "from pprint import pprint\n",
        "pprint(most_relateds)"
      ],
      "metadata": {
        "id": "gKa3ijQc2TP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ea22a9-6462-421f-ae08-8e01cc0b8c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('똑똑하게', 5.852626621112024),\n",
            " ('따라가서', 5.5436417792650055),\n",
            " ('이글루', 5.509046737995528),\n",
            " ('베어그릴스', 5.420709461253241),\n",
            " ('말안하고', 5.3476182061642),\n",
            " ('ㄹㅇㄹㅇㄹㅇ', 5.287448578325152),\n",
            " ('배당금', 5.287448578325152),\n",
            " ('사령관', 5.2702064396566275),\n",
            " ('평화롭게', 5.236867617728502),\n",
            " ('나아서', 5.204947906914405)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 특정 단어['우울']과 컨텍스트가 가장 비슷한 단어 상위 10개##\n",
        "\n",
        "from soynlp.utils import most_similar\n",
        "\n",
        "most_similar('우울', pmi, vocab2idx, idx2vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBlmbVsQotL4",
        "outputId": "587205b5-2309-4ae5-9b7a-2dd245d64e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('심심', 0.22781712789543918),\n",
              " ('불안', 0.20654552217405342),\n",
              " ('우울함', 0.16989673506620928),\n",
              " ('행복', 0.16271023927659378),\n",
              " ('우울증', 0.1625480654125695),\n",
              " ('피곤', 0.1547978316176476),\n",
              " ('우울해', 0.14304488688384553),\n",
              " ('우울하다', 0.13556653025904541),\n",
              " ('불행', 0.13496097718192268),\n",
              " ('우울한', 0.13324270584997489)]"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 텍스트 분석 끝!\n"
      ],
      "metadata": {
        "id": "7P4DZ-4QGXpI"
      }
    }
  ]
}