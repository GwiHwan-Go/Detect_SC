{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQngpG7s9FXTd3wETxwOnd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GwiHwan-Go/Detect_SC/blob/main/Data_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 수집한 데이터를 분석해 봅시다.\n",
        "\n",
        "##### 본 스크립트의 코드들은 3-4분 정도의 연산 시간을 필요로 합니다.\n",
        "##### 실질적인 데이터 분석 및 시각화는 Data_Visualization 스크립트를 참고해주세요.\n",
        "\n",
        "참고 자료 : [딥러닝을 이용한 자연어 처리 입문](!https://wikidocs.net/92961), [SoyNLP 공식 문서](!https://github.com/lovit/soynlp)"
      ],
      "metadata": {
        "id": "QKxKO17zDJGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 준비 사항\n",
        "\n",
        "본 파일은 체험용 코드입니다.\n",
        "\n",
        "실제로 본 파일에 사용된 데이터는 240만 개의 게시글이며, \n",
        "\n",
        "여기서는 간단한 체험을 위해서 체험용 데이터를 제공합니다. \n",
        "\n",
        "또한, 미리 훈련시킨 soyNLP Tokenizer 를 제공하며, \n",
        "\n",
        "다운로드 방법은 아래에서 설명할 것입니다.\n",
        "\n",
        "(수정중)"
      ],
      "metadata": {
        "id": "SFmnvLhjZmen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install soynlp\n",
        "!pip install konlpy\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "eTkSwjJaZ218",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12736447-16fe-414c-ff9b-b19994c675d5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: soynlp in /usr/local/lib/python3.7/dist-packages (0.0.493)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.7.3)\n",
            "Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (5.4.8)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 제공하는 데이터 설명\n",
        "\n",
        "1. 데이터 설명 : DCinside 라는 커뮤니티에서 우울증 갤러리라는 곳의 게시물들의 '제목'들.\n",
        "2. 데이터 오버뷰\n",
        "\n",
        "  - 데이터 크기 : 2,470,236 개\n",
        "\n",
        "  - 데이터 피쳐 : title (텍스트 데이터), author (작성자 id), date (작성 날짜)\n",
        "  \n",
        "3. 텍스트 데이터 : 미리 학습시킨 토크나이저로 토큰화한 데이터로 ' '로 구분되어 있음.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4HpQ_iC9dagz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 다운로드, 파일명은 sns_data.csv 이다.\n",
        "file_name = 'sns_data.csv'\n",
        "!wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-4qx3IRyXUtb_QSItiWyIHZIo9hcBttg' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-4qx3IRyXUtb_QSItiWyIHZIo9hcBttg\" -O $file_name && rm -rf ~/cookies.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcyOFhhbk_lF",
        "outputId": "b7230d58-1fd4-4807-94de-61b6926388a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-30 15:57:09--  https://docs.google.com/uc?export=download&confirm=t&id=1-4qx3IRyXUtb_QSItiWyIHZIo9hcBttg\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.16.113, 142.251.16.139, 142.251.16.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.16.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0o-30-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/tc6oojfhp57aaj44tet8b765iij63j1u/1667145375000/15740322463873228959/*/1-4qx3IRyXUtb_QSItiWyIHZIo9hcBttg?e=download&uuid=69a5a44e-2352-48ed-b198-260deeb7de14 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-10-30 15:57:10--  https://doc-0o-30-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/tc6oojfhp57aaj44tet8b765iij63j1u/1667145375000/15740322463873228959/*/1-4qx3IRyXUtb_QSItiWyIHZIo9hcBttg?e=download&uuid=69a5a44e-2352-48ed-b198-260deeb7de14\n",
            "Resolving doc-0o-30-docs.googleusercontent.com (doc-0o-30-docs.googleusercontent.com)... 142.251.163.132, 2607:f8b0:4004:c1b::84\n",
            "Connecting to doc-0o-30-docs.googleusercontent.com (doc-0o-30-docs.googleusercontent.com)|142.251.163.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 156905939 (150M) [text/csv]\n",
            "Saving to: ‘sns_data.csv’\n",
            "\n",
            "sns_data.csv        100%[===================>] 149.64M   173MB/s    in 0.9s    \n",
            "\n",
            "2022-10-30 15:57:11 (173 MB/s) - ‘sns_data.csv’ saved [156905939/156905939]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 살펴보기\n",
        "\n",
        "data = pd.read_csv(file_name, low_memory=False, index_col=0) \n",
        "first_date, last_date = data.loc[0,'date'], data.loc[data.shape[0]-1,'date']\n",
        "print(\"수집한 게시물 범위 :\", first_date, \"~\", last_date, \"\\n\" \\\n",
        "      \"수집된 데이터 크기 :\", data.shape[0], \"\\n수집한 데이터 features :\", data.columns)\n",
        "data.tail()"
      ],
      "metadata": {
        "id": "325bw-IdzH15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "0dbb1ba3-6ae1-49a7-cd92-08b0cb7668c3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "수집한 게시물 범위 : 2021-03-03 ~ 2022-10-27 \n",
            "수집된 데이터 크기 : 2470236 \n",
            "수집한 데이터 features : Index(['title', 'author', 'date'], dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         title  author        date\n",
              "2470231               나 병신 ...   16125  2022-10-27\n",
              "2470232       나고 닉 글 올리 규 싶 읃데   12779  2022-10-27\n",
              "2470233       씨발 남자 직원 음식 깔아 주    5291  2022-10-27\n",
              "2470234       나도 근데 아이디 두 번 바꿈   15378  2022-10-27\n",
              "2470235  알바 바보 쉨 ㅋㅋㅋ 나도 차단 해봐라   16125  2022-10-27"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8a8f996-9c6d-4bb8-aa9b-02cd4ae2fd91\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2470231</th>\n",
              "      <td>나 병신 ...</td>\n",
              "      <td>16125</td>\n",
              "      <td>2022-10-27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2470232</th>\n",
              "      <td>나고 닉 글 올리 규 싶 읃데</td>\n",
              "      <td>12779</td>\n",
              "      <td>2022-10-27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2470233</th>\n",
              "      <td>씨발 남자 직원 음식 깔아 주</td>\n",
              "      <td>5291</td>\n",
              "      <td>2022-10-27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2470234</th>\n",
              "      <td>나도 근데 아이디 두 번 바꿈</td>\n",
              "      <td>15378</td>\n",
              "      <td>2022-10-27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2470235</th>\n",
              "      <td>알바 바보 쉨 ㅋㅋㅋ 나도 차단 해봐라</td>\n",
              "      <td>16125</td>\n",
              "      <td>2022-10-27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8a8f996-9c6d-4bb8-aa9b-02cd4ae2fd91')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e8a8f996-9c6d-4bb8-aa9b-02cd4ae2fd91 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e8a8f996-9c6d-4bb8-aa9b-02cd4ae2fd91');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 혹시 모를, nan 값을 제거해주자.\n",
        "print(f\"NAN 제거 전 데이터 수 = {data.shape}\")\n",
        "data = data[data.title.isna()==False]\n",
        "data = data.reset_index(drop=True)\n",
        "print(f\"NAN 제거 후 데이터 수 = {data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKx4hSrZxnbX",
        "outputId": "565c0292-a904-40ce-ac2c-5f89507b9d7c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAN 제거 전 데이터 수 = (2469803, 3)\n",
            "NAN 제거 후 데이터 수 = (2469803, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 커스텀 토크나이저 만들기 w/ SoyNLP\n",
        "\n",
        "기존의 토크나이저(konlpy, hanspell 등)들은 대부분 뉴스, 위키백과 등을 학습하여 만들어졌다. \n",
        "\n",
        "하지만, 우리가 오늘 다룰 데이터는 SNS 데이터로 각종 **신조어, 비표준어**가 난무한다.\n",
        "\n",
        "기존의 토크나이저는 이와 같은 데이터를 잘 다루지 못하기 때문에,\n",
        "\n",
        "[SoyNLP](!https://github.com/lovit/soynlp#tokenizer) 에서 제시한 비지도 학습 기반 토크나이저를 채택하였다.\n",
        "\n",
        "이 토크나이저는 동질의 문서의 구조를 학습해서 글자 간의 __응집력__을 통해서 단어를 구분하는 알고리즘으로 설계되었다. \n",
        "\n",
        "자세한 부분은 [공식 문서](!https://github.com/lovit/soynlp#tokenizer)를 참고 해보자."
      ],
      "metadata": {
        "id": "_yhiEncGGbdu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SoyNLP Tokenizer는 학습시키는데, 30분 정도 걸리기 때문에,\n",
        "\n",
        "여기서는 미리 학습시킨 Tokenizer 모델을 제공한다.\n",
        "\n",
        "직접 학습시키고 싶다면, 아래 코드를 돌려보자. \n",
        "\n",
        "더 자세한 내용은 [여기](!https://github.com/lovit/soynlp#tokenizer)에서 확인할 수 있다.\n",
        "\n",
        "```python\n",
        "    from soynlp.word import WordExtractor\n",
        "    word_extractor = WordExtractor()\n",
        "    word_extractor.train(data[data.title.isna()==False].title)\n",
        "    word_score_table = word_extractor.extract()\n",
        "```"
      ],
      "metadata": {
        "id": "jrm6-mASpL8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extractor_name = 'soy_wordExtractor.model'\n",
        "!wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-RrET_of1A3NVWWYnr3PMR-apTZ9dB7J' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-RrET_of1A3NVWWYnr3PMR-apTZ9dB7J\" -O $extractor_name && rm -rf ~/cookies.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NQZlhFhoxnD",
        "outputId": "50f1c586-cb26-4444-8352-fe41ec66d122"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-30 16:07:04--  https://docs.google.com/uc?export=download&confirm=&id=1-RrET_of1A3NVWWYnr3PMR-apTZ9dB7J\n",
            "Resolving docs.google.com (docs.google.com)... 172.253.63.102, 172.253.63.113, 172.253.63.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.253.63.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0o-30-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/amoukcgj7lmivekl7l96pksi2g0t5khv/1667145975000/15740322463873228959/*/1-RrET_of1A3NVWWYnr3PMR-apTZ9dB7J?e=download&uuid=07199435-1b62-4bf1-822c-3106dadee18c [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-10-30 16:07:15--  https://doc-0o-30-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/amoukcgj7lmivekl7l96pksi2g0t5khv/1667145975000/15740322463873228959/*/1-RrET_of1A3NVWWYnr3PMR-apTZ9dB7J?e=download&uuid=07199435-1b62-4bf1-822c-3106dadee18c\n",
            "Resolving doc-0o-30-docs.googleusercontent.com (doc-0o-30-docs.googleusercontent.com)... 142.251.163.132, 2607:f8b0:4004:c1b::84\n",
            "Connecting to doc-0o-30-docs.googleusercontent.com (doc-0o-30-docs.googleusercontent.com)|142.251.163.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 98612779 (94M) [application/octet-stream]\n",
            "Saving to: ‘soy_wordExtractor.model’\n",
            "\n",
            "soy_wordExtractor.m 100%[===================>]  94.04M   175MB/s    in 0.5s    \n",
            "\n",
            "2022-10-30 16:07:16 (175 MB/s) - ‘soy_wordExtractor.model’ saved [98612779/98612779]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from soynlp.word import WordExtractor\n",
        "from soynlp.tokenizer import LTokenizer\n",
        "\n",
        "## Word_Extractor param 설정 및 로드\n",
        "word_extractor = WordExtractor(min_frequency=10,\n",
        "                               min_cohesion_forward=5.0,\n",
        "                               min_right_branching_entropy=0.0)\n",
        "word_extractor.load(extractor_name)\n",
        "\n",
        "## Cohesion 과 Entropy 계산해서 tokenizer 에 필요한 scores 계산\n",
        "scores = word_extractor.word_scores()\n",
        "scores = {key : (scores[key].cohesion_forward * math.exp(scores[key].right_branching_entropy)) \\\n",
        "          for key in scores.keys()}\n",
        "\n",
        "## tokenizer 생성\n",
        "tokenizer = LTokenizer(scores=scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsvzE94CfbQl",
        "outputId": "d9b3d9b2-0364-4d85-8587-9e72a0a3d7dc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all cohesion probabilities was computed. # words = 480337\n",
            "all branching entropies was computed # words = 523918\n",
            "all accessor variety was computed # words = 523918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 커스텀 토크나이저\n",
        "\n",
        "본 분석에서 이용한 커스텀 토크나이저를 소개한다.\n",
        "\n",
        "SoyNLP 토크나이저는 품사 태깅을 하지 못해서 Okt 모듈로 품사 태깅을 한 후에\n",
        "\n",
        "조사를 제외해주었다."
      ],
      "metadata": {
        "id": "8B8CfU-HqTq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## SoyNLP 사용 예 -> SoyNLP(tokenizer) -> okt pos tagger -> 불용어 제거\n",
        "from konlpy.tag import Okt\n",
        "from soynlp.normalizer import *\n",
        "\n",
        "def preprocess_tokenizer(sentence) : \n",
        "\n",
        "  pos_tagger = Okt()\n",
        "\n",
        "  return [word[0]\n",
        "          for word in pos_tagger.pos(' '.join(tokenizer.tokenize(sentence)))\n",
        "          if word[1] != 'Josa'] # 조사는 분석에서 제외\n"
      ],
      "metadata": {
        "id": "HfW3Bm4Dh4HB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 문장을 넣어서 토크나이저의 성능을 체크해보자.\n",
        "play_sentences= \"야이개색야\"\n",
        "preprocess_tokenizer(play_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqgcLcH9qvQl",
        "outputId": "1824d7d4-2c5b-4298-e3a4-6c4adac1cc65"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['야', '이', '개색']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PMI 분석\n",
        "\n",
        "출처 : [SoyNLP 공식문서](!https://github.com/lovit/soynlp/blob/master/tutorials/pmi_usage.ipynb)\n",
        "\n",
        "이제 마지막 단계이다.\n",
        "\n",
        "단어들 간의 연관관계를 분석해서 자살 관련 정보 파악에 도움이 되는 __다른 단어__들은 무엇이 있는 지 알아보자.\n",
        "\n",
        "PMI 분석은\n",
        "\n",
        "(word, contexts) 혹은 (input, outputs)의 상관성을 측정하는 방법으로, pmi 값이 클수록 두 변수의 상관성이 크다.\n",
        "\n",
        "이를 위해서 특정 단어와 그 주위 단어들을 저장하는 행렬인 Word-Contexts Matrix를 생성한다."
      ],
      "metadata": {
        "id": "_Lc8B1z7zgSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1분 30초 걸림\n",
        "from soynlp.vectorizer import sent_to_word_contexts_matrix\n",
        "from scipy import sparse\n",
        "import pickle\n",
        "from soynlp.word import pmi as pmi_func\n",
        "\n",
        "x, idx2vocab = sent_to_word_contexts_matrix(\n",
        "    data.title,\n",
        "    windows=3,\n",
        "    min_tf=10,\n",
        "    tokenizer= lambda x:x.split(), # (default) lambda x:x.split(),\n",
        "    dynamic_weight=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "pmi, px, py = pmi_func(\n",
        "    x,\n",
        "    min_pmi = 0,\n",
        "    alpha = 0.0,\n",
        "    beta = 0.75\n",
        ")"
      ],
      "metadata": {
        "id": "kYCoGn58zyjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b5c3931-14b8-49a0-8ecb-b371edbfe480"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create (word, contexts) matrix\n",
            "  - counting word frequency from 2469802 sents, mem=1.771 Gb\n",
            "  - scanning (word, context) pairs from 2469802 sents, mem=2.756 Gb\n",
            "  - (word, context) matrix was constructed. shape = (49771, 49771)                    \n",
            "  - done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 결과\n",
        "\n",
        "이제 우울증 갤러리에서 주로 얘기되는 단어들 간의 연결관계를 알 수 있다.\n",
        "\n",
        "- Context Words : 비슷한 문맥을 가지는 단어.\n",
        "\n",
        "- Similar Words : 문맥이 비슷한 단어.\n",
        "\n",
        "target 변수에 알고싶은 단어를 넣어서 더 자세히 알아보자."
      ],
      "metadata": {
        "id": "dVUtb9A1sH3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 특정 단어['살고 싶다']와 함께 등장한 단어들 상위 10개##\n",
        "target = '자살'\n",
        "howmany = 10\n",
        "\n",
        "vocab2idx = {vocab:idx for idx, vocab in enumerate(idx2vocab)}\n",
        "query = vocab2idx[target]\n",
        "\n",
        "submatrix = pmi[query,:].tocsr() # get the row of query\n",
        "contexts = submatrix.nonzero()[1] # nonzero() return (rows, columns)\n",
        "pmi_i = submatrix.data\n",
        "\n",
        "most_relateds = [(idx, pmi_ij) for idx, pmi_ij in zip(contexts, pmi_i)]\n",
        "most_relateds = sorted(most_relateds, key=lambda x:-x[1])[:howmany]\n",
        "most_relateds = [(idx2vocab[idx], pmi_ij) for idx, pmi_ij in most_relateds]\n",
        "\n",
        "from pprint import pprint\n",
        "pprint(most_relateds)"
      ],
      "metadata": {
        "id": "gKa3ijQc2TP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ab35f95-760a-4d99-f964-38a2d5aa3907"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('도피', 6.844622458591964),\n",
            " ('삵', 6.031369397834147),\n",
            " ('살고싶은데', 5.772712722570554),\n",
            " ('뽁뽁', 5.685233690813876),\n",
            " ('했데', 5.524714801301454),\n",
            " ('좆피', 5.288600593862374),\n",
            " ('자살', 5.274353861018971),\n",
            " ('머애', 5.262282104003921),\n",
            " ('은부', 5.249461278984446),\n",
            " ('대왕고래', 5.23685594024716)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 특정 단어['우울']과 컨텍스트가 가장 비슷한 단어 상위 10개##\n",
        "\n",
        "from soynlp.utils import most_similar\n",
        "\n",
        "most_similar('우울', pmi, vocab2idx, idx2vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBlmbVsQotL4",
        "outputId": "cb6d6f5b-af86-41a7-bad5-57189a181ffb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('심심', 0.22781712789543906),\n",
              " ('불안', 0.20654552217405342),\n",
              " ('우울함', 0.16989673506620928),\n",
              " ('행복', 0.16271023927659367),\n",
              " ('우울증', 0.1625480654125695),\n",
              " ('피곤', 0.15479783161764749),\n",
              " ('우울해', 0.14304488688384542),\n",
              " ('우울하다', 0.1355665302590453),\n",
              " ('불행', 0.13496097718192268),\n",
              " ('우울한', 0.13324270584997489)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 텍스트 분석 끝!\n"
      ],
      "metadata": {
        "id": "7P4DZ-4QGXpI"
      }
    }
  ]
}